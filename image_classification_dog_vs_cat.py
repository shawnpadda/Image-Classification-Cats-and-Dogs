# -*- coding: utf-8 -*-
"""Image Classification dog vs cat.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XrscK5wpBLKFvmzFwQqgWNox7S6eum6x

Mounting google drive in google colab.
"""

from google.colab import drive
drive.mount('/content/drive')

"""Load all of the essential libraries."""

import matplotlib.pyplot as plt
import numpy as np
import os
import PIL
import tensorflow as tf

from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential

"""Load training and test set"""

data = '/content/drive/MyDrive/dataset/training_set'
data1 = '/content/drive/MyDrive/dataset/test_set'

"""Train set

Validation set /test set
"""

train = tf.keras.preprocessing.image_dataset_from_directory(
    data,seed = 123, image_size = (180,180), batch_size = 32
)

"""Continue"""

validation = tf.keras.preprocessing.image_dataset_from_directory(
    data1,seed = 123, image_size = (180,180), batch_size = 32
)

class_names = train.class_names
print(class_names)

class_names = validation.class_names
print(class_names)

"""Visualize the training data images"""

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 10))
for images, labels in train.take(1):
  for i in range(9):
    ax = plt.subplot(3, 3, i + 1)
    plt.imshow(images[i].numpy().astype("uint8"))
    plt.title(class_names[labels[i]])
    plt.axis("off")

"""Normalize the data"""

norm_layer = layers.experimental.preprocessing.Rescaling(1./255)

"""Create a model - Convolutional neural network (CNN)."""

classes = 2
img_height = 180
img_width = 180
model = Sequential([
  layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),
  layers.Conv2D(16, 3, activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(32, 3, activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(64, 3, activation='relu'),
  layers.MaxPooling2D(),
  layers.Flatten(),
  layers.Dense(128, activation='relu'),
  layers.Dense(classes)
])

"""Compile the model"""

model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

"""Print the model summary."""

model.summary()

"""Train the model"""

epochs=1
history = model.fit(
  train,
  validation_data=validation,
  epochs=epochs
)

"""Predict the performance of the model.

"""

sunflower_url = "https://upload.wikimedia.org/wikipedia/commons/d/db/Tallinn_Zoo_Ovis_dalli_2.jpg"
sunflower_path = tf.keras.utils.get_file('Tallinn_Zoo_Ovis_dalli_2', origin=sunflower_url)

img = keras.preprocessing.image.load_img(
    sunflower_path, target_size=(img_height, img_width)
)
img_array = keras.preprocessing.image.img_to_array(img)
img_array = tf.expand_dims(img_array, 0) # Create a batch

predictions = model.predict(img_array)
score = tf.nn.softmax(predictions[0])

print(
    "This image most likely belongs to {} with a {:.2f} percent confidence."
    .format(class_names[np.argmax(score)], 100 * np.max(score))
)